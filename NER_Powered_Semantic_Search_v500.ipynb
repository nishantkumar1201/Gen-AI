{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e559f380",
   "metadata": {},
   "source": [
    "# NER Powered Semantic Search Using Pinecone v5.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e537aef3",
   "metadata": {},
   "source": [
    "### Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38eac55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init pinecone\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "# API_KEY = \"YOUR API KEY\"\n",
    "pc = Pinecone(api_key = API_KEY)\n",
    "\n",
    "index = pc.Index(\"medium-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fd00bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up pinecone index, after deleting all vectors if you run it again you will get error\n",
    "\n",
    "index.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b80055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete index , dimension no longer useful\n",
    "pc.delete_index(\"medium-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbcc0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries for NER \n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6969324",
   "metadata": {},
   "source": [
    "### NER Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a3c9844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# init NER engine\n",
    "\n",
    "model_id = 'dslim/bert-base-NER'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_id)\n",
    "\n",
    "# nlp pipeline\n",
    "\n",
    "nlp = pipeline('ner',\n",
    "              model=model,\n",
    "              tokenizer=tokenizer,\n",
    "              aggregation_strategy= 'max',\n",
    "              device= 'cpu') \n",
    "# nlp(\"Bill Gates is the founder of Microsoft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da04c986",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2747186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries for retriever\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# https://huggingface.co/flax-sentence-embeddings/all_datasets_v3_mpnet-base\n",
    "retriever = SentenceTransformer(\n",
    "    \"flax-sentence-embeddings/all_datasets_v3_mpnet-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3142139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pinecone Index\n",
    "pc.create_index(\"medium-data\", dimension= 768, metric=\"cosine\",\n",
    "                     spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f75c34e-1700-4984-827d-568503d4bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "index= pc.Index(\"medium-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31bb742",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a39745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9247ab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/mohsin/.cache/huggingface/datasets/fabiochiu___csv/fabiochiu--medium-articles-96791ff68926910d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "# Obtain Raw Data\n",
    "\n",
    "df = load_dataset(\n",
    "    \"fabiochiu/medium-articles\",\n",
    "    data_files=\"medium_articles.csv\",\n",
    "    split=\"train\"\n",
    ").to_pandas()\n",
    "\n",
    "df = df.dropna().sample(10000, random_state=45) # might take 30mins to 1hr\n",
    "\n",
    "df['text_extended'] = df['title'] + '.' + df['text'].str[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dc3255a-255a-4f0d-8950-aec1b35e9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase your internet is slow and couldn't make \"dataset\" works, you can download the file I uploaded as \"medium_articles_10k.csv\"\n",
    "# Source of data: https://www.kaggle.com/code/fabiochiusano/medium-articles-simple-data-analysis?select=medium_articles.csv\n",
    "# it is the same underlying data\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"medium_articles_10k.csv\")\n",
    "df = df.dropna().sample(1000, random_state=45) # \n",
    "df['text_extended'] = df['title'] + '.' + df['text'].str[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11d8c94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tags</th>\n",
       "      <th>text_extended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>3577</td>\n",
       "      <td>Why You’re Struggling with Innovation. And How...</td>\n",
       "      <td>The modern typewriter had a problem. When Chri...</td>\n",
       "      <td>https://jswilder16.medium.com/why-youre-strugg...</td>\n",
       "      <td>['Jake Wilder']</td>\n",
       "      <td>2019-04-22 01:46:42.469000+00:00</td>\n",
       "      <td>['Management', 'Leadership', 'Innovation', 'Cr...</td>\n",
       "      <td>Why You’re Struggling with Innovation. And How...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>7003</td>\n",
       "      <td>#085 | Debugging Vue Sites Displaying Blank Pages</td>\n",
       "      <td>So I had this bright idea to consolidate all m...</td>\n",
       "      <td>https://medium.com/footprints-on-the-sand/085-...</td>\n",
       "      <td>['Kelvin Zhao']</td>\n",
       "      <td>2020-03-24 23:11:00.960000+00:00</td>\n",
       "      <td>['Vuejs', 'Website Development', 'Debugging', ...</td>\n",
       "      <td>#085 | Debugging Vue Sites Displaying Blank Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>925</td>\n",
       "      <td>You won’t believe what I’m going to tell you a...</td>\n",
       "      <td>You won’t believe what I’m going to tell you a...</td>\n",
       "      <td>https://medium.com/pnewton84/he-discovered-a-n...</td>\n",
       "      <td>['Paul Newton']</td>\n",
       "      <td>2017-09-19 19:26:41.376000+00:00</td>\n",
       "      <td>['Marketing', 'Digital Marketing', 'Facebook',...</td>\n",
       "      <td>You won’t believe what I’m going to tell you a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>3233</td>\n",
       "      <td>How Emotionally Intelligent People Deal With T...</td>\n",
       "      <td>This reminds me of the time I was on the way h...</td>\n",
       "      <td>https://medium.com/curious/how-emotionally-int...</td>\n",
       "      <td>['Ayodeji Awosika']</td>\n",
       "      <td>2020-11-09 20:50:40.841000+00:00</td>\n",
       "      <td>['Emotional Intelligence', 'Mental Health', 'I...</td>\n",
       "      <td>How Emotionally Intelligent People Deal With T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>3515</td>\n",
       "      <td>What’s New in React 16 and Fiber Explanation</td>\n",
       "      <td>Previously, React would block the entire threa...</td>\n",
       "      <td>https://medium.com/edge-coders/react-16-featur...</td>\n",
       "      <td>['Trey Huffine']</td>\n",
       "      <td>2018-10-30 13:57:05.603000+00:00</td>\n",
       "      <td>['Code', 'Tech', 'React', 'JavaScript', 'Start...</td>\n",
       "      <td>What’s New in React 16 and Fiber Explanation.P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              title  \\\n",
       "3577        3577  Why You’re Struggling with Innovation. And How...   \n",
       "7003        7003  #085 | Debugging Vue Sites Displaying Blank Pages   \n",
       "925          925  You won’t believe what I’m going to tell you a...   \n",
       "3233        3233  How Emotionally Intelligent People Deal With T...   \n",
       "3515        3515       What’s New in React 16 and Fiber Explanation   \n",
       "\n",
       "                                                   text  \\\n",
       "3577  The modern typewriter had a problem. When Chri...   \n",
       "7003  So I had this bright idea to consolidate all m...   \n",
       "925   You won’t believe what I’m going to tell you a...   \n",
       "3233  This reminds me of the time I was on the way h...   \n",
       "3515  Previously, React would block the entire threa...   \n",
       "\n",
       "                                                    url              authors  \\\n",
       "3577  https://jswilder16.medium.com/why-youre-strugg...      ['Jake Wilder']   \n",
       "7003  https://medium.com/footprints-on-the-sand/085-...      ['Kelvin Zhao']   \n",
       "925   https://medium.com/pnewton84/he-discovered-a-n...      ['Paul Newton']   \n",
       "3233  https://medium.com/curious/how-emotionally-int...  ['Ayodeji Awosika']   \n",
       "3515  https://medium.com/edge-coders/react-16-featur...     ['Trey Huffine']   \n",
       "\n",
       "                             timestamp  \\\n",
       "3577  2019-04-22 01:46:42.469000+00:00   \n",
       "7003  2020-03-24 23:11:00.960000+00:00   \n",
       "925   2017-09-19 19:26:41.376000+00:00   \n",
       "3233  2020-11-09 20:50:40.841000+00:00   \n",
       "3515  2018-10-30 13:57:05.603000+00:00   \n",
       "\n",
       "                                                   tags  \\\n",
       "3577  ['Management', 'Leadership', 'Innovation', 'Cr...   \n",
       "7003  ['Vuejs', 'Website Development', 'Debugging', ...   \n",
       "925   ['Marketing', 'Digital Marketing', 'Facebook',...   \n",
       "3233  ['Emotional Intelligence', 'Mental Health', 'I...   \n",
       "3515  ['Code', 'Tech', 'React', 'JavaScript', 'Start...   \n",
       "\n",
       "                                          text_extended  \n",
       "3577  Why You’re Struggling with Innovation. And How...  \n",
       "7003  #085 | Debugging Vue Sites Displaying Blank Pa...  \n",
       "925   You won’t believe what I’m going to tell you a...  \n",
       "3233  How Emotionally Intelligent People Deal With T...  \n",
       "3515  What’s New in React 16 and Fiber Explanation.P...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6fd0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(nlp(df_batch)) # list of lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f065d7",
   "metadata": {},
   "source": [
    "### NER Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3253d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for extracting entities of a batch of texts\n",
    "\n",
    "def extract_entities(list_of_text):\n",
    "    entities = []\n",
    "    for doc in list_of_text: \n",
    "        entities.append([item['word'] for item in nlp(doc)])\n",
    "        # list of entities for 1 doc\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75ba2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "\n",
    "# len(retriever.encode(df_batch))\n",
    "# len(retriever.encode(df_batch[0])) # try for one doc\n",
    "# embedding for batch\n",
    "# emb = retriever.encode(df_batch).tolist() # array to python list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b819cc",
   "metadata": {},
   "source": [
    "### Batch Upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ff7ce8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# upsert data\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    i_end = min(i+batch_size, len(df))\n",
    "    # print(i, i_end) # starting and ending index of each batch\n",
    "    \n",
    "    # get a batch of data\n",
    "    df_batch = df.iloc[i: i_end].copy()\n",
    "    \n",
    "    # embedding\n",
    "    emb = retriever.encode(df_batch['text_extended'].tolist()\n",
    "                          ).tolist() # array to python list\n",
    "    \n",
    "    # ner extraction\n",
    "    entities = extract_entities(df_batch['text_extended'].tolist())\n",
    "    \n",
    "    # [[]] --> [set1, set2, ], remove duplicate entities    \n",
    "    df_batch['named_entity'] = [list(set(entity)) for entity in entities] # one list per document\n",
    "    \n",
    "    # create meta data\n",
    "    df_batch = df_batch.drop('text', axis=1)\n",
    "    \n",
    "    meta_data = df_batch.to_dict(orient='records') # pd.df to dictionary\n",
    "    \n",
    "    # create ids\n",
    "    \n",
    "    ids = [f\"{idx}\" for idx in range(i, i_end)] #\n",
    "    \n",
    "    # upsert\n",
    "    \n",
    "    vectors_to_upsert = list(zip(ids, emb, meta_data))  # nd array to python list\n",
    "    \n",
    "    _ = index.upsert(vectors= vectors_to_upsert)  \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0bb86227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5c5e5",
   "metadata": {},
   "source": [
    "### Query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28a42866",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to make a Wordpress website?\"  # Natural Language\n",
    "\n",
    "emb_qx = retriever.encode(query).tolist() # embedded query vector\n",
    "\n",
    "ne = extract_entities([query])[0] # Named entity as a search filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89ccbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = index.query(vector=emb_qx, top_k= 5, include_metadata=True,\n",
    "           filter = {\"named_entity\": {\"$in\" : ne}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01d0d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might not find any match if you are only upserting 1k data because of insufficient data there might not be good match, \n",
    "# try to load more data or tweak query based on data (glance over pinecone console and look for text_extended field in your vectors)\n",
    "for result in xc['matches']:\n",
    "    print(result['score'], \" \", result['metadata']['named_entity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "773447ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to learn NLP?\"  # Natural Language\n",
    "\n",
    "emb_qx = retriever.encode(query).tolist() # embedded query vector\n",
    "\n",
    "ne = extract_entities([query])[0] # Named entity as a search filter\n",
    "\n",
    "xc = index.query(vector=emb_qx, top_k= 5, include_metadata=True,\n",
    "           filter = {\"named_entity\": {\"$in\" : ne}  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca0dcd7d-8be7-4f0e-8c20-004c2e84ff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28366977   ['Allen', 'Allen NLP', 'NLP', 'PyTorch']\n",
      "0.263163775   ['Python', 'Harnham', 'NLP', 'LDA', 'Science', 'London', 'Datatech Analytics', 'Data']\n",
      "0.241720855   ['NLP', 'Lambda Layer']\n",
      "0.236823067   ['The Dark Tower', 'It', 'NLP', 'Text Mining', 'Carrie', 'Stephen King', 'King', 'Under the Dome', 'The Shining']\n",
      "0.211078629   ['AI', 'ML', 'NLP', 'Your Weekly AI', 'Machine Learning and Data Science']\n"
     ]
    }
   ],
   "source": [
    "for result in xc['matches']:\n",
    "    print(result['score'], \" \", result['metadata']['named_entity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556796b-29cd-4635-b31f-e9d5a7fd9197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
